{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mtrand.RandomState at 0x2798125a1b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reading in the data that was prepared for modeling. In the notebook Feature Engineering and Pre-processing, we ensured that our X variable and test data had the same features so that any trained model would be able to predict the probability of West Nile virus in our testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../../Data/X.csv',index_col=[0])\n",
    "y = pd.read_csv('../../Data/y.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Before modeling, it is important to train test split. This is done so that we can later test to make sure that our model is able to predict accurately on unseen data. In this specific case, we are training our model on 70 percent of our data, and then testing it on the remaining 30 percent. By stratifying on our y variable, we are saying that we want the proportion of cases where West Nile virus is present to be the same in both the testing and training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y['WnvPresent'], test_size=0.3, random_state=42,stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Pipelines are a way to streamline a lot of the routine processes by encapsulating little pieces of logic into one function call, making it easier to model our data. They are set up with the fit/transform/predict functionality so that you could fit a whole pipeline to the training data while also transforming the test data without having to do each step individually. The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a ‘__’. In the model below, we set Standard Scaler and Logistic Regression as its 'steps' parameters in order to tell our pipeline which estimators we want to fit. We can see that we fit them both while also finding optimal parameters all in one step. \n",
    ">>Step 1: Standardization of datasets is an important requirement for many machine learning estimators. Datasets that are not standardized will cause problems for models because they do not more or less look like standard normally distributed data (Gaussian with zero mean and unit variance). We can use Standard Scaler, a preprocessing module, to standardize features by removing the mean and scaling to unit variance. It scales data by dividing non-constant features by their standard deviation. This is the most used module due to the fact that it computes the mean and standard deviation on a training set so as to be able to later reapply the same transformation on the testing set. By using Standard Scaler, we are allowing each feature to be considered on the same scale as one another. This makes our computations more efficient.\n",
    "\n",
    ">> Step 2: Logistic regression performs well in binary outcomes. Because the y varaible is either 0 or 1, we have an idea that Logistic Regression will be a good choice. Also, the betas of Logistic Regression are easy to interpret compared to other models because they are the log of odds. Therefore, in order to properly interpret the coefficient of this model, we need to exponentiate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "       ('ss',StandardScaler()),\n",
    "       ('LR',LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This cell specifies the specific hyper Parameters that we want to test to see which combination of hyper parameters perform the best. These hyper parameters are:\n",
    ">> penalty: This parameter determines which regularization to optimize on. If it is l1, this means that it is using lasso regularization, which minimizes the sum of squared errors plus the sum of the absolute value of the coefficients. l2 uses ridge regularization, which minimizes the sum of squared errors plus the sum of the square of the coefficients squared\n",
    "    \n",
    ">> C: This parameter determines the strength of regularization. The smaller C is, the stronger regularization is.\n",
    "    \n",
    ">> class weight: This parameter weights our classes' importance based on how many times each class occurs. What this means conceptually is that it makes the cases that do have west Nile virus have more weight than cases that do not have West Nile virus, because there are few cases of West Nile virus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "   'LR__penalty':['l1','l2'],\n",
    "   'LR__C':[.25,.5,.75,1],\n",
    "   'LR__class_weight':['balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Grid Search is a module that performs parameter tuning. Parameter tuning is the process of selecting the values for a model’s parameters that maximize the accuracy of the model. Grid Search does this by exhaustively generating candidates from a grid of parameter values specified with the `param_grid` parameter. When “fitting” Grid Search on a dataset, all the possible combinations of parameter values are evaluated, and the best combination is chosen. In our case, we peform Grid Search in order to find the parameters that give us the highest score.\n",
    ">>Instead of scoring the model with accuracy, we scored the model with `roc_auc` , which stands for receiver operating characteristic area under the curve. This is used to evaluate the performance of a binary classification system, and gives us insight into how our model is doing. It does this because our classes are unbalanced. We could predict zero for every data point, and could have a 95% accuracy score because 95% of the data is in our negative class. Using `roc_auc` accounts for the true positives and true negatives that we predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('ss', StandardScaler(copy=True, with_mean=True, with_std=True)), ('LR', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'LR__penalty': ['l1', 'l2'], 'LR__C': [0.25, 0.5, 0.75, 1], 'LR__class_weight': ['balanced']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = GridSearchCV(pipe,param_grid=params,scoring='roc_auc')\n",
    "LogReg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for LR__C that had the highest roc_auc score is 0.25\n",
      "The value for LR__class_weight that had the highest roc_auc score is balanced\n",
      "The value for LR__penalty that had the highest roc_auc score is l1\n"
     ]
    }
   ],
   "source": [
    "for params in LogReg.best_params_:\n",
    "    print('The value for',params,'that had the highest roc_auc score is',LogReg.best_params_[params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score of the model is 0.7965616690362456\n",
      "The testing score of the model is 0.7873116839638434\n"
     ]
    }
   ],
   "source": [
    "print('The training score of the model is',LogReg.score(X_train,y_train))\n",
    "print('The testing score of the model is',LogReg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../Assets/LogReg.pkl','wb+') as f:\n",
    "    pickle.dump(LogReg,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
