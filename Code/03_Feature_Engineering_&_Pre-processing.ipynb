{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering/Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mtrand.RandomState at 0x23bd46e33f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pickle\n",
    "np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../Data/clean_test.csv',index_col=[0])\n",
    "train = pd.read_csv('../Data/clean_train.csv',index_col=[0])\n",
    "weather = pd.read_csv('../Data/clean_weather.csv',index_col=[0])\n",
    "spray = pd.read_csv('../Data/clean_spray.csv',index_col=[0])\n",
    "for df in [train,spray,test,weather]:\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index(df['Date'],inplace=True)\n",
    "    df.drop(columns='Date',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Feature Engineering/Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">After research, it was discovered that the amount of daylight in a day is an important feature in determining the amount of mosquitoes in a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Daylight'] = (weather['Sunset'] - weather['Sunrise'])/100\n",
    "weather.drop(columns=['Sunset','Sunrise'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Using the Feature CodeSum, the columns Rain and fog were created to indicate if it was either raining or if it was foggy that day. This may be useful as a feature because mosquitoes can not fly in either rain or fog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_contain(x,string):\n",
    "    if string in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "weather['Rain'] = weather[\"CodeSum\"].apply(lambda x: string_contain(x,\"RA\"))\n",
    "weather['Fog'] = weather['CodeSum'].apply(lambda x: string_contain(x,'FG'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This cell creates a new column 'Humidity.' This feature was engineered because based on outside research, it was discovered that mosquitoes thrive in humid environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_celcius(tf):\n",
    "    tc= (tf -32)/1.8\n",
    "    return tc\n",
    "def humidity(t, td):\n",
    "    a= 17.625\n",
    "    b= 243.04\n",
    "    rh= 100 * (np.exp((a * td)/(b + td)))/(np.exp((a * t)/(b + t)))\n",
    "    return round(rh, 2)\n",
    "weather.loc[:, 'Celcius_Dew']= change_to_celcius(weather['DewPoint'])\n",
    "weather['Tavg']= weather['Tavg'].astype(float)\n",
    "weather.loc[:, 'Celcius_Temp']= change_to_celcius(weather['Tavg'])\n",
    "weather.loc[:, 'Humidity']= humidity(weather['Celcius_Temp'], weather['Celcius_Dew'])\n",
    "weather.drop(columns = ['Celcius_Temp','Celcius_Dew','DewPoint'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">By making two separate data frames for each station, we can better manage creating the averages/sums for the previous 7 days for certain features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "station1_weather, station2_weather = weather.groupby(by=\"Station\")\n",
    "station1_weather = station1_weather[1]\n",
    "station2_weather = station2_weather[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This cell creates a new feature that described either the mean of the previous 7 days, or the number of days out of the previous 7 days that an event occurred. For example, prev_7_day_avg_Precip describes the average precipitation over 7 days, and prev_7_day_Rain describes the number of days out of the previous 7 that it rained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in [station1_weather,station2_weather]:\n",
    "    station['prev_7_day_avg_Precip'] = station['PrecipTotal'].rolling(7).mean()\n",
    "    station['prev_7_day_avg_Temp'] = station['Tavg'].rolling(7).mean()\n",
    "    station['prev_7_day_Rain'] = station['Rain'].rolling(7).sum()\n",
    "    station['prev_7_day_Fog'] = station['Fog'].rolling(7).sum()\n",
    "    station['prev_7_day_Daylight'] = station['Daylight'].rolling(7).mean()\n",
    "    station.drop(columns=['PrecipTotal','Tavg','Rain','Fog','Daylight','Heat','Cool'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Dropping Columns that are no longer needed/may be co-linearly related to other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in [station1_weather,station2_weather]:\n",
    "    station.drop(columns=['CodeSum','Tmin','Tmax','Station'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Creating columns that describe the presence of each species in a trap for both train and testing data, this is done so that our computer can \"read\" categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,pd.get_dummies(train['Species'])],axis=1)\n",
    "test = pd.concat([test,pd.get_dummies(test['Species'])],axis=1)\n",
    "test.drop(columns=['Species'],inplace=True)\n",
    "train.drop(columns=['Species'],inplace=True)\n",
    "train = pd.concat([train,pd.get_dummies(train['Block'],prefix = \"Block\")],axis=1)\n",
    "test = pd.concat([test,pd.get_dummies(test['Block'],prefix = \"Block\")],axis=1)\n",
    "test.drop(columns=['Block','Trap'],inplace=True)\n",
    "train.drop(columns=['Block','Trap'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">What this cell tells us is that we need to manually create the UNSPECIFIED CULEX feature in our training dataframe. Id should only be in the testing dataframe, and NumMosquitos and WnvPresent should only be in training by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The {'UNSPECIFIED CULEX', 'Block_26', 'Id'} Features are in our first dataframe,but not in the second dataframe\n",
      "The {'WnvPresent', 'NumMosquitos'} Features are in our second dataframe,but not in the first dataframe\n"
     ]
    }
   ],
   "source": [
    "def column_check(df1,df2):\n",
    "    if (len(set(df1.columns) - set(df2.columns)) == 0) & (len(set(df2.columns) - set(df1.columns)) == 0):\n",
    "        print('These Dataframes have the same columns')\n",
    "    else:\n",
    "        print('The',set(df1.columns) - set(df2.columns),'Features are in our first dataframe,but not in the second dataframe')\n",
    "        print('The',set(df2.columns) - set(df1.columns),'Features are in our second dataframe,but not in the first dataframe')\n",
    "column_check(test,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['UNSPECIFIED CULEX'] = 0\n",
    "train['Block_26'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This cell does the same thing as the previous one, but for the month and year of each trap that was collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [test,train]:\n",
    "    dates = df.index\n",
    "    df['Month'] = df.index.map(lambda dates: dates.month)\n",
    "    df['Year'] = df.index.map(lambda dates: dates.year)\n",
    "    df['Year_sq'] = df['Year'] * df['Year']\n",
    "    df['Month_sq'] = df['Month'] * df['Month']\n",
    "    df.drop(columns = ['Month','Year'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The {'Id'} Features are in our first dataframe,but not in the second dataframe\n",
      "The {'WnvPresent', 'NumMosquitos'} Features are in our second dataframe,but not in the first dataframe\n"
     ]
    }
   ],
   "source": [
    "column_check(test,train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This cell splits both our training and testing data on a specific latitude line into two data frames for train, and two dataframes for test. This is done to assign a station's weather data to the traps that are closest to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "station1_train= train[train.Latitude > 41.85]\n",
    "station2_train= train[train.Latitude <= 41.85]\n",
    "station1_test= test[test.Latitude > 41.85]\n",
    "station2_test= test[test.Latitude <= 41.85]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This cell merges our training and testing data frame with the correct weather station's data frame, then recombines the two training dataframes back together, and the two testing dataframes back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat1= pd.merge(station1_weather, station1_train, how= 'inner', right_index= True, left_index= True)\n",
    "stat2= pd.merge(station2_weather, station2_train, how= 'inner', right_index= True, left_index= True)\n",
    "stat_test1= pd.merge(station1_weather, station1_test, how= 'inner', right_index= True, left_index= True)\n",
    "stat_test2= pd.merge(station2_weather, station2_test, how= 'inner', right_index= True, left_index= True)\n",
    "train = pd.concat([stat1, stat2],sort=True)\n",
    "test = pd.concat([stat_test1,stat_test2],sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The {'Id'} Features are in our first dataframe,but not in the second dataframe\n",
      "The {'NumMosquitos', 'WnvPresent'} Features are in our second dataframe,but not in the first dataframe\n"
     ]
    }
   ],
   "source": [
    "column_check(test,train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating X and y Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Because the outcome that we want predict is the presence of West Nile virus, it becomes the y variable. Everything else meant to predict West Nile virus becomes our X variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[['WnvPresent']]\n",
    "X = train.drop(columns=['WnvPresent', 'NumMosquitos'])\n",
    "y_stuff = train[['NumMosquitos']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This cell is saving our list of ID's so we can submit to Kaggle later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id_for_test = test['Id']\n",
    "test.drop(columns='Id',inplace = True)\n",
    "with open('../Assets/ID_list.pkl','wb+') as f:\n",
    "    pickle.dump(Id_for_test,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The cell below confirms that our X variable and our training data have the same values. Therefore, we are ready to start making models and making predictions based on our testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These Dataframes have the same columns\n"
     ]
    }
   ],
   "source": [
    "column_check(test,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to CSV for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('../Data/X.csv')\n",
    "y.to_csv('../Data/y.csv')\n",
    "test.to_csv('../Data/formatted_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
